{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1648108144526,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "J1V0MgSM5Qqk"
   },
   "outputs": [],
   "source": [
    "# MBTI 디시인사이드 갤러리(한글) 모델 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3105,
     "status": "ok",
     "timestamp": 1648108147627,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "S9FLom9AFTKN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import pickle\n",
    "import os.path\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import spacy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 123122,
     "status": "ok",
     "timestamp": 1648108270747,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "rBv31GcXfP2x"
   },
   "outputs": [],
   "source": [
    "# INTP 데이터 전처리\n",
    "INTP_c = pd.read_csv(('./MBTI_Crawling/INTP_content.csv'), encoding='cp949', header=None)\n",
    "INTP_t = pd.read_csv(('./MBTI_Crawling/INTP_title.csv'), encoding='cp949', header=None)\n",
    "INTP2_c = pd.read_csv(('./MBTI_Crawling/INTP2_content.csv'), encoding='cp949', header=None)\n",
    "INTP2_t = pd.read_csv(('./MBTI_Crawling/INTP2_title.csv'), encoding='cp949', header=None)\n",
    "INTP_c = INTP_c.transpose()\n",
    "INTP_t = INTP_t.transpose()\n",
    "INTP2_c = INTP2_c.transpose()\n",
    "INTP2_t = INTP2_t.transpose()\n",
    "INTP = pd.concat([INTP_c,INTP_t,INTP2_c,INTP2_t], axis=0)\n",
    "INTP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "INTP = INTP.iloc[:15000]\n",
    "INTP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(INTP[0][0+a*10])+\" \"+str(INTP[0][1+a*10])+\" \"+str(INTP[0][2+a*10])+\" \"+str(INTP[0][3+a*10])+\" \"+str(INTP[0][4+a*10])+\" \"\\\n",
    "          +str(INTP[0][5+a*10])+\" \"+str(INTP[0][6+a*10])+\" \"+str(INTP[0][7+a*10])+\" \"+str(INTP[0][8+a*10])+\" \"+str(INTP[0][9+a*10])+\" \"\n",
    "    INTP_list.append(word)\n",
    "INTP_word = pd.DataFrame()\n",
    "INTP_word['posts'] = INTP_list\n",
    "INTP_word['type'] = INTP_word['posts'].apply(lambda x:'INTP')\n",
    "INTP = INTP_word\n",
    "\n",
    "# INFP 데이터 전처리\n",
    "INFP_c = pd.read_csv(('./MBTI_Crawling/INFP_content.csv'), encoding='cp949', header=None)\n",
    "INFP_t = pd.read_csv(('./MBTI_Crawling/INFP_title.csv'), encoding='cp949', header=None)\n",
    "INFP_2c = pd.read_csv(('./MBTI_Crawling/INFP2_content.csv'), encoding='cp949', header=None)\n",
    "INFP_2t = pd.read_csv(('./MBTI_Crawling/INFP2_title.csv'), encoding='cp949', header=None)\n",
    "INFP_c = INFP_c.transpose()\n",
    "INFP_t = INFP_t.transpose()\n",
    "INFP_2c = INFP_2c.transpose()\n",
    "INFP_2t = INFP_2t.transpose()\n",
    "INFP = pd.concat([INFP_2c,INFP_2t,INFP_c,INFP_t], axis=0)\n",
    "INFP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "INFP = INFP.iloc[:15000]\n",
    "INFP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(INFP[0][0+a*10])+\" \"+str(INFP[0][1+a*10])+\" \"+str(INFP[0][2+a*10])+\" \"+str(INFP[0][3+a*10])+\" \"+str(INFP[0][4+a*10])+\" \"\\\n",
    "          +str(INFP[0][5+a*10])+\" \"+str(INFP[0][6+a*10])+\" \"+str(INFP[0][7+a*10])+\" \"+str(INFP[0][8+a*10])+\" \"+str(INFP[0][9+a*10])+\" \"\n",
    "    INFP_list.append(word)\n",
    "INFP_word = pd.DataFrame()\n",
    "INFP_word['posts'] = INFP_list\n",
    "INFP_word['type'] = INFP_word['posts'].apply(lambda x:'INFP')\n",
    "INFP = INFP_word\n",
    "\n",
    "# ISFP 데이터 전처리\n",
    "ISFP_c = pd.read_csv(('./MBTI_Crawling/ISFP_content.csv'), encoding='cp949', header=None)\n",
    "ISFP_t = pd.read_csv(('./MBTI_Crawling/ISFP_title.csv'), encoding='cp949', header=None)\n",
    "ISFP_2c = pd.read_csv(('./MBTI_Crawling/ISFP2_content.csv'), encoding='cp949', header=None)\n",
    "ISFP_2t = pd.read_csv(('./MBTI_Crawling/ISFP2_title.csv'), encoding='cp949', header=None)\n",
    "ISFP_c = ISFP_c.transpose()\n",
    "ISFP_t = ISFP_t.transpose()\n",
    "ISFP_2c = ISFP_2c.transpose()\n",
    "ISFP_2t = ISFP_2t.transpose()\n",
    "ISFP = pd.concat([ISFP_2c,ISFP_2t,ISFP_c,ISFP_t], axis=0)\n",
    "ISFP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ISFP = ISFP.iloc[:15000]\n",
    "ISFP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ISFP[0][0+a*10])+\" \"+str(ISFP[0][1+a*10])+\" \"+str(ISFP[0][2+a*10])+\" \"+str(ISFP[0][3+a*10])+\" \"+str(ISFP[0][4+a*10])+\" \"\\\n",
    "          +str(ISFP[0][5+a*10])+\" \"+str(ISFP[0][6+a*10])+\" \"+str(ISFP[0][7+a*10])+\" \"+str(ISFP[0][8+a*10])+\" \"+str(ISFP[0][9+a*10])+\" \"\n",
    "    ISFP_list.append(word)\n",
    "ISFP_word = pd.DataFrame()\n",
    "ISFP_word['posts'] = ISFP_list\n",
    "ISFP_word['type'] = ISFP_word['posts'].apply(lambda x:'ISFP')\n",
    "ISFP = ISFP_word\n",
    "\n",
    "# ISTP 데이터 전처리\n",
    "ISTP_c = pd.read_csv(('./MBTI_Crawling/ISTP_content.csv'), encoding='cp949', header=None)\n",
    "ISTP_t = pd.read_csv(('./MBTI_Crawling/ISTP_title.csv'), encoding='cp949', header=None)\n",
    "ISTP_2c = pd.read_csv(('./MBTI_Crawling/ISTP2_content.csv'), encoding='cp949', header=None)\n",
    "ISTP_2t = pd.read_csv(('./MBTI_Crawling/ISTP2_title.csv'), encoding='cp949', header=None)\n",
    "ISTP_c = ISTP_c.transpose()\n",
    "ISTP_t = ISTP_t.transpose()\n",
    "ISTP_2c = ISTP_2c.transpose()\n",
    "ISTP_2t = ISTP_2t.transpose()\n",
    "ISTP = pd.concat([ISTP_c,ISTP_t,ISTP_2c,ISTP_2t], axis=0)\n",
    "ISTP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ISTP = ISTP.iloc[:15000]\n",
    "ISTP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ISTP[0][0+a*10])+\" \"+str(ISTP[0][1+a*10])+\" \"+str(ISTP[0][2+a*10])+\" \"+str(ISTP[0][3+a*10])+\" \"+str(ISTP[0][4+a*10])+\" \"\\\n",
    "          +str(ISTP[0][5+a*10])+\" \"+str(ISTP[0][6+a*10])+\" \"+str(ISTP[0][7+a*10])+\" \"+str(ISTP[0][8+a*10])+\" \"+str(ISTP[0][9+a*10])+\" \"\n",
    "    ISTP_list.append(word)\n",
    "ISTP_word = pd.DataFrame()\n",
    "ISTP_word['posts'] = ISTP_list\n",
    "ISTP_word['type'] = ISTP_word['posts'].apply(lambda x:'ISTP')\n",
    "ISTP = ISTP_word\n",
    "\n",
    "# ISTJ 데이터 전처리\n",
    "ISTJ_c = pd.read_csv(('./MBTI_Crawling/ISTJ_content.csv'), encoding='cp949', header=None)\n",
    "ISTJ_t = pd.read_csv(('./MBTI_Crawling/ISTJ_title.csv'), encoding='cp949', header=None)\n",
    "ISTJ_c = ISTJ_c.transpose()\n",
    "ISTJ_t = ISTJ_t.transpose()\n",
    "ISTJ = pd.concat([ISTJ_c,ISTJ_t], axis=0)\n",
    "ISTJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ISTJ = ISTJ.iloc[:15000]\n",
    "ISTJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ISTJ[0][0+a*10])+\" \"+str(ISTJ[0][1+a*10])+\" \"+str(ISTJ[0][2+a*10])+\" \"+str(ISTJ[0][3+a*10])+\" \"+str(ISTJ[0][4+a*10])+\" \"\\\n",
    "          +str(ISTJ[0][5+a*10])+\" \"+str(ISTJ[0][6+a*10])+\" \"+str(ISTJ[0][7+a*10])+\" \"+str(ISTJ[0][8+a*10])+\" \"+str(ISTJ[0][9+a*10])+\" \"\n",
    "    ISTJ_list.append(word)\n",
    "ISTJ_word = pd.DataFrame()\n",
    "ISTJ_word['posts'] = ISTJ_list\n",
    "ISTJ_word['type'] = ISTJ_word['posts'].apply(lambda x:'ISTJ')\n",
    "ISTJ = ISTJ_word\n",
    "\n",
    "# ISFJ 데이터 전처리\n",
    "ISFJ_t = pd.read_csv(('./MBTI_Crawling/ISFJ_title.csv'), encoding='cp949', header=None)\n",
    "ISFJ_t = ISFJ_t.transpose()\n",
    "ISFJ = pd.concat([ISFJ_t], axis=0)\n",
    "ISFJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ISFJ = ISFJ.iloc[:15000]\n",
    "ISFJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ISFJ[0][0+a*10])+\" \"+str(ISFJ[0][1+a*10])+\" \"+str(ISFJ[0][2+a*10])+\" \"+str(ISFJ[0][3+a*10])+\" \"+str(ISFJ[0][4+a*10])+\" \"\\\n",
    "          +str(ISFJ[0][5+a*10])+\" \"+str(ISFJ[0][6+a*10])+\" \"+str(ISFJ[0][7+a*10])+\" \"+str(ISFJ[0][8+a*10])+\" \"+str(ISFJ[0][9+a*10])+\" \"\n",
    "    ISFJ_list.append(word)\n",
    "ISFJ_word = pd.DataFrame()\n",
    "ISFJ_word['posts'] = ISFJ_list\n",
    "ISFJ_word['type'] = ISFJ_word['posts'].apply(lambda x:'ISFJ')\n",
    "ISFJ = ISFJ_word\n",
    "\n",
    "# INFJ 데이터 전처리\n",
    "INFJ_c = pd.read_csv(('./MBTI_Crawling/INFJ_content.csv'), encoding='cp949', header=None)\n",
    "INFJ_t = pd.read_csv(('./MBTI_Crawling/INFJ_title.csv'), encoding='cp949', header=None)\n",
    "INFJ_c = INFJ_c.transpose()\n",
    "INFJ_t = INFJ_t.transpose()\n",
    "INFJ = pd.concat([INFJ_c,INFJ_t], axis=0)\n",
    "INFJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "INFJ = INFJ.iloc[:15000]\n",
    "INFJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(INFJ[0][0+a*10])+\" \"+str(INFJ[0][1+a*10])+\" \"+str(INFJ[0][2+a*10])+\" \"+str(INFJ[0][3+a*10])+\" \"+str(INFJ[0][4+a*10])+\" \"\\\n",
    "          +str(INFJ[0][5+a*10])+\" \"+str(INFJ[0][6+a*10])+\" \"+str(INFJ[0][7+a*10])+\" \"+str(INFJ[0][8+a*10])+\" \"+str(INFJ[0][9+a*10])+\" \"\n",
    "    INFJ_list.append(word)\n",
    "INFJ_word = pd.DataFrame()\n",
    "INFJ_word['posts'] = INFJ_list\n",
    "INFJ_word['type'] = INFJ_word['posts'].apply(lambda x:'INFJ')\n",
    "INFJ = INFJ_word\n",
    "\n",
    "# INTJ 데이터 전처리\n",
    "INTJ_c = pd.read_csv(('./MBTI_Crawling/INTJ_content.csv'), encoding='cp949', header=None)\n",
    "INTJ_t = pd.read_csv(('./MBTI_Crawling/INTJ_title.csv'), encoding='cp949', header=None)\n",
    "INTJ_c = INTJ_c.transpose()\n",
    "INTJ_t = INTJ_t.transpose()\n",
    "INTJ = pd.concat([INTJ_c,INTJ_t], axis=0)\n",
    "INTJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "INTJ = INTJ.iloc[:15000]\n",
    "INTJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(INTJ[0][0+a*10])+\" \"+str(INTJ[0][1+a*10])+\" \"+str(INTJ[0][2+a*10])+\" \"+str(INTJ[0][3+a*10])+\" \"+str(INTJ[0][4+a*10])+\" \"\\\n",
    "          +str(INTJ[0][5+a*10])+\" \"+str(INTJ[0][6+a*10])+\" \"+str(INTJ[0][7+a*10])+\" \"+str(INTJ[0][8+a*10])+\" \"+str(INTJ[0][9+a*10])+\" \"\n",
    "    INTJ_list.append(word)\n",
    "INTJ_word = pd.DataFrame()\n",
    "INTJ_word['posts'] = INTJ_list\n",
    "INTJ_word['type'] = INTJ_word['posts'].apply(lambda x:'INTJ')\n",
    "INTJ = INTJ_word\n",
    "\n",
    "# ENTJ 데이터 전처리\n",
    "ENTJ_c = pd.read_csv(('./MBTI_Crawling/ENTJ_content.csv'), encoding='cp949', header=None)\n",
    "ENTJ_t = pd.read_csv(('./MBTI_Crawling/ENTJ_title.csv'), encoding='cp949', header=None)\n",
    "ENTJ_c = ENTJ_c.transpose()\n",
    "ENTJ_t = ENTJ_t.transpose()\n",
    "ENTJ = pd.concat([ENTJ_c,ENTJ_t], axis=0)\n",
    "ENTJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ENTJ = ENTJ.iloc[:15000]\n",
    "ENTJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ENTJ[0][0+a*10])+\" \"+str(ENTJ[0][1+a*10])+\" \"+str(ENTJ[0][2+a*10])+\" \"+str(ENTJ[0][3+a*10])+\" \"+str(ENTJ[0][4+a*10])+\" \"\\\n",
    "          +str(ENTJ[0][5+a*10])+\" \"+str(ENTJ[0][6+a*10])+\" \"+str(ENTJ[0][7+a*10])+\" \"+str(ENTJ[0][8+a*10])+\" \"+str(ENTJ[0][9+a*10])+\" \"\n",
    "    ENTJ_list.append(word)\n",
    "ENTJ_word = pd.DataFrame()\n",
    "ENTJ_word['posts'] = ENTJ_list\n",
    "ENTJ_word['type'] = ENTJ_word['posts'].apply(lambda x:'ENTJ')\n",
    "ENTJ = ENTJ_word\n",
    "\n",
    "# ENFJ 데이터 전처리\n",
    "ENFJ_c = pd.read_csv(('./MBTI_Crawling/ENFJ_content.csv'), encoding='cp949', header=None)\n",
    "ENFJ_t = pd.read_csv(('./MBTI_Crawling/ENFJ_title.csv'), encoding='cp949', header=None)\n",
    "ENFJ_c = ENFJ_c.transpose()\n",
    "ENFJ_t = ENFJ_t.transpose()\n",
    "ENFJ = pd.concat([ENFJ_c,ENFJ_t], axis=0)\n",
    "ENFJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ENFJ = ENFJ.iloc[:15000]\n",
    "ENFJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ENFJ[0][0+a*10])+\" \"+str(ENFJ[0][1+a*10])+\" \"+str(ENFJ[0][2+a*10])+\" \"+str(ENFJ[0][3+a*10])+\" \"+str(ENFJ[0][4+a*10])+\" \"\\\n",
    "          +str(ENFJ[0][5+a*10])+\" \"+str(ENFJ[0][6+a*10])+\" \"+str(ENFJ[0][7+a*10])+\" \"+str(ENFJ[0][8+a*10])+\" \"+str(ENFJ[0][9+a*10])+\" \"\n",
    "    ENFJ_list.append(word)\n",
    "ENFJ_word = pd.DataFrame()\n",
    "ENFJ_word['posts'] = ENFJ_list\n",
    "ENFJ_word['type'] = ENFJ_word['posts'].apply(lambda x:'ENFJ')\n",
    "ENFJ = ENFJ_word\n",
    "\n",
    "# ESFJ 데이터 전처리\n",
    "ESFJ_c = pd.read_csv(('./MBTI_Crawling/ESFJ_content.csv'), encoding='cp949', header=None)\n",
    "ESFJ_t = pd.read_csv(('./MBTI_Crawling/ESFJ_title.csv'), encoding='cp949', header=None)\n",
    "ESFJ_c = ESFJ_c.transpose()\n",
    "ESFJ_t = ESFJ_t.transpose()\n",
    "ESFJ = pd.concat([ESFJ_c,ESFJ_t], axis=0)\n",
    "ESFJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ESFJ = ESFJ.iloc[:15000]\n",
    "ESFJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ESFJ[0][0+a*10])+\" \"+str(ESFJ[0][1+a*10])+\" \"+str(ESFJ[0][2+a*10])+\" \"+str(ESFJ[0][3+a*10])+\" \"+str(ESFJ[0][4+a*10])+\" \"\\\n",
    "          +str(ESFJ[0][5+a*10])+\" \"+str(ESFJ[0][6+a*10])+\" \"+str(ESFJ[0][7+a*10])+\" \"+str(ESFJ[0][8+a*10])+\" \"+str(ESFJ[0][9+a*10])+\" \"\n",
    "    ESFJ_list.append(word)\n",
    "ESFJ_word = pd.DataFrame()\n",
    "ESFJ_word['posts'] = ESFJ_list\n",
    "ESFJ_word['type'] = ESFJ_word['posts'].apply(lambda x:'ESFJ')\n",
    "ESFJ = ESFJ_word\n",
    "\n",
    "# ESTJ 데이터 전처리\n",
    "ESTJ_c = pd.read_csv(('./MBTI_Crawling/ESTJ_content.csv'), encoding='cp949', header=None)\n",
    "ESTJ_t = pd.read_csv(('./MBTI_Crawling/ESTJ_title.csv'), encoding='cp949', header=None)\n",
    "ESTJ_c = ESTJ_c.transpose()\n",
    "ESTJ_t = ESTJ_t.transpose()\n",
    "ESTJ = pd.concat([ESTJ_c,ESTJ_t], axis=0)\n",
    "ESTJ.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ESTJ = ESTJ.iloc[:15000]\n",
    "ESTJ_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ESTJ[0][0+a*10])+\" \"+str(ESTJ[0][1+a*10])+\" \"+str(ESTJ[0][2+a*10])+\" \"+str(ESTJ[0][3+a*10])+\" \"+str(ESTJ[0][4+a*10])+\" \"\\\n",
    "          +str(ESTJ[0][5+a*10])+\" \"+str(ESTJ[0][6+a*10])+\" \"+str(ESTJ[0][7+a*10])+\" \"+str(ESTJ[0][8+a*10])+\" \"+str(ESTJ[0][9+a*10])+\" \"\n",
    "    ESTJ_list.append(word)\n",
    "ESTJ_word = pd.DataFrame()\n",
    "ESTJ_word['posts'] = ESTJ_list\n",
    "ESTJ_word['type'] = ESTJ_word['posts'].apply(lambda x:'ESTJ')\n",
    "ESTJ = ESTJ_word\n",
    "\n",
    "# ESTP 데이터 전처리\n",
    "ESTP_c = pd.read_csv(('./MBTI_Crawling/ESTP_content.csv'), encoding='cp949', header=None)\n",
    "ESTP_t = pd.read_csv(('./MBTI_Crawling/ESTP_title.csv'), encoding='cp949', header=None)\n",
    "ESTP_c = ESTP_c.transpose()\n",
    "ESTP_t = ESTP_t.transpose()\n",
    "ESTP = pd.concat([ESTP_c,ESTP_t], axis=0)\n",
    "ESTP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ESTP = ESTP.iloc[:15000]\n",
    "ESTP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ESTP[0][0+a*10])+\" \"+str(ESTP[0][1+a*10])+\" \"+str(ESTP[0][2+a*10])+\" \"+str(ESTP[0][3+a*10])+\" \"+str(ESTP[0][4+a*10])+\" \"\\\n",
    "          +str(ESTP[0][5+a*10])+\" \"+str(ESTP[0][6+a*10])+\" \"+str(ESTP[0][7+a*10])+\" \"+str(ESTP[0][8+a*10])+\" \"+str(ESTP[0][9+a*10])+\" \"\n",
    "    ESTP_list.append(word)\n",
    "ESTP_word = pd.DataFrame()\n",
    "ESTP_word['posts'] = ESTP_list\n",
    "ESTP_word['type'] = ESTP_word['posts'].apply(lambda x:'ESTP')\n",
    "ESTP = ESTP_word\n",
    "\n",
    "# ESFP 데이터 전처리\n",
    "ESFP_c = pd.read_csv(('./MBTI_Crawling/ESFP_content.csv'), encoding='cp949', header=None)\n",
    "ESFP_t = pd.read_csv(('./MBTI_Crawling/ESFP_title.csv'), encoding='cp949', header=None)\n",
    "ESFP_c = ESFP_c.transpose()\n",
    "ESFP_t = ESFP_t.transpose()\n",
    "ESFP = pd.concat([ESFP_c,ESFP_t], axis=0)\n",
    "ESFP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ESFP = ESFP.iloc[:15000]\n",
    "ESFP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ESFP[0][0+a*10])+\" \"+str(ESFP[0][1+a*10])+\" \"+str(ESFP[0][2+a*10])+\" \"+str(ESFP[0][3+a*10])+\" \"+str(ESFP[0][4+a*10])+\" \"\\\n",
    "          +str(ESFP[0][5+a*10])+\" \"+str(ESFP[0][6+a*10])+\" \"+str(ESFP[0][7+a*10])+\" \"+str(ESFP[0][8+a*10])+\" \"+str(ESFP[0][9+a*10])+\" \"\n",
    "    ESFP_list.append(word)\n",
    "ESFP_word = pd.DataFrame()\n",
    "ESFP_word['posts'] = ESFP_list\n",
    "ESFP_word['type'] = ESFP_word['posts'].apply(lambda x:'ESFP')\n",
    "ESFP = ESFP_word\n",
    "\n",
    "# ENTP 데이터 전처리\n",
    "ENTP_c = pd.read_csv(('./MBTI_Crawling/ENTP_content.csv'), encoding='cp949', header=None)\n",
    "ENTP_t = pd.read_csv(('./MBTI_Crawling/ENTP_title.csv'), encoding='cp949', header=None)\n",
    "ENTP_c = ENTP_c.transpose()\n",
    "ENTP_t = ENTP_t.transpose()\n",
    "ENTP = pd.concat([ENTP_c,ENTP_t], axis=0)\n",
    "ENTP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ENTP = ENTP.iloc[:15000]\n",
    "ENTP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ENTP[0][0+a*10])+\" \"+str(ENTP[0][1+a*10])+\" \"+str(ENTP[0][2+a*10])+\" \"+str(ENTP[0][3+a*10])+\" \"+str(ENTP[0][4+a*10])+\" \"\\\n",
    "          +str(ENTP[0][5+a*10])+\" \"+str(ENTP[0][6+a*10])+\" \"+str(ENTP[0][7+a*10])+\" \"+str(ENTP[0][8+a*10])+\" \"+str(ENTP[0][9+a*10])+\" \"\n",
    "    ENTP_list.append(word)\n",
    "ENTP_word = pd.DataFrame()\n",
    "ENTP_word['posts'] = ENTP_list\n",
    "ENTP_word['type'] = ENTP_word['posts'].apply(lambda x:'ENTP')\n",
    "ENTP = ENTP_word\n",
    "\n",
    "# ENFP 데이터 전처리\n",
    "ENFP_c = pd.read_csv(('./MBTI_Crawling/ENFP_content.csv'), encoding='cp949', header=None)\n",
    "ENFP_t = pd.read_csv(('./MBTI_Crawling/ENFP_title.csv'), encoding='cp949', header=None)\n",
    "ENFP_c = ENFP_c.transpose()\n",
    "ENFP_t = ENFP_t.transpose()\n",
    "ENFP = pd.concat([ENFP_c,ENFP_t], axis=0)\n",
    "ENFP.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ENFP = ENFP.iloc[:15000]\n",
    "ENFP_list =[]\n",
    "for a in range(1500):\n",
    "    word = str(ENFP[0][0+a*10])+\" \"+str(ENFP[0][1+a*10])+\" \"+str(ENFP[0][2+a*10])+\" \"+str(ENFP[0][3+a*10])+\" \"+str(ENFP[0][4+a*10])+\" \"\\\n",
    "          +str(ENFP[0][5+a*10])+\" \"+str(ENFP[0][6+a*10])+\" \"+str(ENFP[0][7+a*10])+\" \"+str(ENFP[0][8+a*10])+\" \"+str(ENFP[0][9+a*10])+\" \"\n",
    "    ENFP_list.append(word)\n",
    "ENFP_word = pd.DataFrame()\n",
    "ENFP_word['posts'] = ENFP_list\n",
    "ENFP_word['type'] = ENFP_word['posts'].apply(lambda x:'ENFP')\n",
    "ENFP = ENFP_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1648108270748,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "OWUtrLoUH3LC"
   },
   "outputs": [],
   "source": [
    "# MBTI별 데이터셋 MBTI으로 통합\n",
    "MBTI = pd.concat([INFP,INTP,ISFP,ISTP,ENFP,ENTP,ESFP,ESTP,ENFJ,ENTJ,ESFJ,ESTJ,ISTJ,ISFJ,INFJ,INTJ], axis=0)\n",
    "# [INFP,INTP,ISFP,ISTP],[ENFP,ENTP,ESFP,ESTP],[ENFJ,ENTJ,ESFJ,ESTJ],[ISTJ,ISFJ,INFJ,INTJ]\n",
    "# MBTI를 column에 따라 분할\n",
    "MBTI_type =  MBTI['type']\n",
    "MBTI_posts = MBTI['posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1648108271349,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "EqcmBBPVH4l0",
    "outputId": "6a2c0577-5e6a-4b5f-d50c-8b20371b36e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # dataframe을 csv파일로 저장\n",
    "MBTI.to_csv('./MBTI_통합본.csv')\n",
    "MBTI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648108271349,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "eZnxEsD_KfTS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(MBTI_posts, MBTI_type,\n",
    "                                                   test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648108271350,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "qoNTSWw2KfwU"
   },
   "outputs": [],
   "source": [
    "recreate_model=False\n",
    "filename = 'MBTI_svm_v2.sav'\n",
    "if not os.path.isfile(filename):\n",
    "    recreate_model=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2214,
     "status": "ok",
     "timestamp": 1648108273561,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "WnVRCzFUKhsK"
   },
   "outputs": [],
   "source": [
    "# Check if need to recreate the model\n",
    "if recreate_model:    \n",
    "    \n",
    "    # Creating an instance to vectorizer:\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Training the vectorizer:\n",
    "    x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "    \n",
    "    # Training the classifier:\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(x_train_tfidf, y_train)\n",
    "    \n",
    "    # Pipelining the vectorizer and the classifier\n",
    "    text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])\n",
    "    text_clf.fit(x_train, y_train)\n",
    "    \n",
    "    # saving the model to disk\n",
    "    pickle.dump(text_clf, open(filename, 'wb'))\n",
    "\n",
    "# If there is no need to recreate the model, just open the file from the disk    \n",
    "else:\n",
    "    # loading the model from disk\n",
    "    text_clf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648108273562,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "c2JbTS9KKi8m"
   },
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1648108274174,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "EWqWl27UKkOT",
    "outputId": "5047e4dd-aced-4a94-f869-d299872678a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.22      0.22      0.22       297\n",
      "        ENFP       0.17      0.18      0.17       297\n",
      "        ENTJ       0.21      0.21      0.21       298\n",
      "        ENTP       0.39      0.41      0.40       287\n",
      "        ESFJ       0.23      0.19      0.21       323\n",
      "        ESFP       0.23      0.22      0.23       287\n",
      "        ESTJ       0.38      0.39      0.38       298\n",
      "        ESTP       0.24      0.25      0.25       312\n",
      "        INFJ       0.22      0.22      0.22       287\n",
      "        INFP       0.22      0.21      0.21       296\n",
      "        INTJ       0.36      0.39      0.37       290\n",
      "        INTP       0.27      0.23      0.25       333\n",
      "        ISFJ       0.62      0.75      0.68       326\n",
      "        ISFP       0.15      0.14      0.15       278\n",
      "        ISTJ       0.16      0.19      0.18       280\n",
      "        ISTP       0.26      0.23      0.24       311\n",
      "\n",
      "    accuracy                           0.28      4800\n",
      "   macro avg       0.27      0.28      0.27      4800\n",
      "weighted avg       0.27      0.28      0.27      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1648108705139,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "WWxebgCRKlN9"
   },
   "outputs": [],
   "source": [
    "# 판타지\n",
    "fantasy = pd.read_csv('./Naver_Movie_Review_Combination/Fantasy_Combination.csv', encoding='utf-8', index_col=0)\n",
    "# fantasy = fantasy.transpose()\n",
    "# fantasy.rename(columns = {0:'posts'},inplace=True)\n",
    "fantasy['Word'] = fantasy['Word'].astype(str)\n",
    "fantasy_test = fantasy['Word']\n",
    "predictions = text_clf.predict(fantasy_test)\n",
    "predictions = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1648108274176,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "8-0gjprRKt9A"
   },
   "outputs": [],
   "source": [
    "# 로맨스\n",
    "romance = pd.read_csv('MBTI-romance.csv', encoding='cp949', header=None)\n",
    "romance = romance.transpose()\n",
    "romance.rename(columns = {0:'posts'},inplace=True)\n",
    "romance['posts'] = romance['posts'].astype(str)\n",
    "romance_test = romance['posts']\n",
    "predictions = text_clf.predict(romance_test)\n",
    "predictions = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648108708473,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "EbFMq6VfKmsP",
    "outputId": "3d474e2d-48cf-4857-a412-b575eb5e5181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTP : 6.737931034482758%\n",
      "INFP : 7.696551724137931%\n",
      "ISTP : 3.593103448275862%\n",
      "ISFP : 10.517241379310345%\n",
      "ENTP : 9.10344827586207%\n",
      "ENFP : 3.3448275862068964%\n",
      "ESTP : 2.6620689655172414%\n",
      "ESFP : 3.013793103448276%\n",
      "ESTJ : 5.241379310344827%\n",
      "ESFJ : 8.50344827586207%\n",
      "ENTJ : 5.089655172413793%\n",
      "ENFJ : 5.958620689655173%\n",
      "ISTJ : 6.924137931034482%\n",
      "ISFJ : 2.1724137931034484%\n",
      "INFJ : 13.924137931034483%\n",
      "INTJ : 5.517241379310345%\n"
     ]
    }
   ],
   "source": [
    "print('INTP : ' + str((predictions.count('INTP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('INFP : ' + str((predictions.count('INFP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ISTP : ' + str((predictions.count('ISTP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ISFP : ' + str((predictions.count('ISFP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ENTP : ' + str((predictions.count('ENTP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ENFP : ' + str((predictions.count('ENFP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ESTP : ' + str((predictions.count('ESTP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ESFP : ' + str((predictions.count('ESFP')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ESTJ : ' + str((predictions.count('ESTJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ESFJ : ' + str((predictions.count('ESFJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ENTJ : ' + str((predictions.count('ENTJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ENFJ : ' + str((predictions.count('ENFJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ISTJ : ' + str((predictions.count('ISTJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('ISFJ : ' + str((predictions.count('ISFJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('INFJ : ' + str((predictions.count('INFJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')\n",
    "print('INTJ : ' + str((predictions.count('INTJ')/(\n",
    "       predictions.count('INTP')+predictions.count('INFP')+\n",
    "       predictions.count('ISTP')+predictions.count('ISFP')+\n",
    "       predictions.count('ESTJ')+predictions.count('ESFJ')+\n",
    "       predictions.count('ENTJ')+predictions.count('ENFJ')+\n",
    "       predictions.count('ESFP')+predictions.count('ESTP')+\n",
    "       predictions.count('ENFP')+predictions.count('ENTP')+\n",
    "       predictions.count('ISTJ')+predictions.count('ISFJ')+\n",
    "       predictions.count('INFJ')+predictions.count('INTJ'))\n",
    "      )*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1648108274178,
     "user": {
      "displayName": "상진박",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgRhQAQ4s1cDPP684HYOchikZ4hSSwTGU-YUMXspA=s64",
      "userId": "06054429427164180292"
     },
     "user_tz": -540
    },
    "id": "djbyLKiyhbTL"
   },
   "outputs": [],
   "source": [
    "predictions.count('INTJ')/1500"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNoI3ByuxOQ3E3ycmFaGU2i",
   "mount_file_id": "1dQa80HyaculVYCZ83hhswIWpkWYw7u0k",
   "name": "MBTI_1row:10words",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
